{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries\n",
    "- Taking as example/guide 3D-Organ repository -> https://github.com/lmcanavals/3D-ORGAN/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install tensorflow keras keras-complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Flatten, Dense, Reshape, LeakyReLU, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Activation, Conv3DTranspose, Conv3D\n",
    "from keras.layers import Embedding, Lambda, Concatenate, Add, BatchNormalization\n",
    "from keras.layers import GlobalAvgPool3D, Multiply, LeakyReLU\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def dense_layer(inp, f, act='relu', bn=True):\n",
    "    initializer = act if act is not None else ''\n",
    "    initializer = 'he_uniform' if initializer.find('relu') != -1 else 'glorot_uniform'\n",
    "    out = Dense(f, use_bias=False, kernel_initializer=initializer)(inp)\n",
    "    if bn: out = BatchNormalization()(out)\n",
    "    \n",
    "    if act == 'lrelu':\n",
    "        out = LeakyReLU(alpha=0.2)(out)\n",
    "    elif act is not None:\n",
    "        out = Activation(act)(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def conv_layer(inp, f, k=4, s=2, p='same', act='relu', bn=True, transpose=False,\n",
    "               se=False, se_ratio=16):\n",
    "    initializer = act if act is not None else ''\n",
    "    initializer = 'he_uniform' if initializer.find('relu') != -1 else 'glorot_uniform'\n",
    "    fun = Conv3DTranspose if transpose else Conv3D\n",
    "    out = fun(f, k, strides=s, padding=p, use_bias=False, kernel_initializer=initializer)(inp)\n",
    "    if bn: out = BatchNormalization()(out)\n",
    "    \n",
    "    if act == 'lrelu':\n",
    "        out = LeakyReLU(alpha=0.2)(out)\n",
    "    elif act is not None:\n",
    "        out = Activation(act)(out)\n",
    "\n",
    "    # squeeze and excite\n",
    "    if se:\n",
    "        out_se = GlobalAvgPool3D()(out)\n",
    "        r = f // se_ratio if (f // se_ratio) > 0 else 1\n",
    "        out_se = Reshape((1, 1, f))(out_se)\n",
    "        out_se = Dense(r, use_bias=False, kernel_initializer='he_uniform',\n",
    "                       activation='relu')(out_se)\n",
    "        out_se = Dense(f, use_bias=False, activation='sigmoid')(out_se)\n",
    "        out = Multiply()([out, out_se])\n",
    "    \n",
    "    return out\n",
    "\n",
    "def generator():\n",
    "    input_layer = Input(shape=(700, 500, 3))  # Adjust dimensions based on your 2D images\n",
    "\n",
    "    x = dense_layer(input_layer, 128)\n",
    "    x = Reshape((700, 500, 128))(x)\n",
    "\n",
    "    x = conv_layer(x, 64, transpose=True)\n",
    "    x = conv_layer(x, 128, transpose=True)\n",
    "    x = conv_layer(x, 256, transpose=True)\n",
    "\n",
    "    output_layer = Conv3DTranspose(1, kernel_size=(3, 3, 3), strides=(2, 2, 2), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def discriminator():\n",
    "    input_2d = Input(shape=(700, 500, 3))\n",
    "    input_3d = Input(shape=(32, 32, 32, 3))\n",
    "\n",
    "    x = conv_layer(input_2d, 64)\n",
    "    x = conv_layer(x, 128)\n",
    "    x = conv_layer(x, 256)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = dense_layer(x, 1, act='sigmoid', bn=False)\n",
    "\n",
    "    model = Model(inputs=[input_2d, input_3d], outputs=x)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generator() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dele/Documents/Machine_learning/TF/models.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dele/Documents/Machine_learning/TF/models.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m input_2d \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(\u001b[39m700\u001b[39m, \u001b[39m500\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dele/Documents/Machine_learning/TF/models.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m input_3d \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(\u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dele/Documents/Machine_learning/TF/models.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m generated_3d \u001b[39m=\u001b[39m generator(input_2d)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dele/Documents/Machine_learning/TF/models.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m validity \u001b[39m=\u001b[39m discriminator([input_2d, generated_3d])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dele/Documents/Machine_learning/TF/models.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Compile the combined model\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: generator() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "# Function to load 2D image data from .npy files\n",
    "def load_2d_data(folder_path):\n",
    "    data = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".npy\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            image = np.load(file_path)\n",
    "            data.append(image)\n",
    "    return np.array(data)\n",
    "\n",
    "# Load 2D data\n",
    "input_2d_data = load_2d_data('/home/dele/Documents/Machine_learning/TF/Train2D_Data/')\n",
    "\n",
    "# Load 3D voxel data\n",
    "input_3d_data = np.load('/home/dele/Documents/Machine_learning/TF/voxel_data.npy',allow_pickle=True)\n",
    "# Combined model\n",
    "input_2d = Input(shape=(700, 500, 3))\n",
    "input_3d = Input(shape=(32, 32, 32, 3))\n",
    "\n",
    "generated_3d = generator(input_2d)\n",
    "validity = discriminator([input_2d, generated_3d])\n",
    "\n",
    "# Compile the combined model\n",
    "combined_model = Model([input_2d, input_3d], validity)\n",
    "combined_model.compile(loss=['binary_crossentropy'], optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Labels (assuming you have your labels ready)\n",
    "labels = np.ones((len(input_2d_data), 1))\n",
    "\n",
    "# Train the combined model\n",
    "combined_model.fit([input_2d_data, input_3d_data], labels, epochs=5, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
